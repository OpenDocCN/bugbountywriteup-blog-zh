<html>
<head>
<title>WHEN CLUSTERING MEETS CYBER-SECURITY:</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">当集群遇到网络安全时:</h1>
<blockquote>原文：<a href="https://infosecwriteups.com/when-clustering-meets-cyber-security-24ed8d5392ad?source=collection_archive---------5-----------------------#2022-10-22">https://infosecwriteups.com/when-clustering-meets-cyber-security-24ed8d5392ad?source=collection_archive---------5-----------------------#2022-10-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="08be" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">机器学习和算法:</h2></div><h2 id="bc7e" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">无监督方法:</h2><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/fe313da729ed3f25c8de6415b4567551.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eQHhmievYNwvBUH0OkJeJQ.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated"><a class="ae lr" href="https://c1.wallpaperflare.com/preview/299/412/959/star-clusters-globular-cluster-star-star-formation.jpg" rel="noopener ugc nofollow" target="_blank">https://C1 . wallpaperflare . com/preview/299/412/959/star-clusters-global-cluster-star-star-formation . jpg</a></figcaption></figure><p id="6732" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">你们好，可爱的人们。我希望你做得很好，不断进步，并从工作和学习中获得最大收益。我们又回到了数据科学领域中最不受重视的话题之一，这也是学习和使用最重要、最愉快的话题，也是许多算法和机器学习模型的基础。例如，在聚类介绍中，我们将看到一系列内容，如它如何工作、如何实施、我们为什么使用聚类、聚类中使用的算法、如何通过不同的算法识别数据模式等等。</p><p id="4eca" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">所以让我们开始吧。</p><p id="dcea" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">让我们从头开始看</p><h2 id="e916" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">机器学习的定义。</h2><p id="4c08" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">→机器学习(ML)是对计算机算法的研究，它根据经验(即历史数据)自动学习和改进，而无需显式编程。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mq"><img src="../Images/b2083abe384a7927403c853e1b27758b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GgCT71zWBMPQoZwi"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">作者图片</figcaption></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mr"><img src="../Images/ac331842b3ee07bae5bfb6578a824c3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XU22i56aQgmsAKZN"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated"><a class="ae lr" href="https://i.pinimg.com/564x/7d/e0/5a/7de05a6b16c82c80ca1d88a82ea6727c.jpg" rel="noopener ugc nofollow" target="_blank">https://I . pinimg . com/564 x/7d/E0/5a/7de 05 a 6b 16 c 82 c 80 ca 1d 88 a 82 ea 6727 c . jpg</a></figcaption></figure><p id="be2b" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">尝试用2分钟分析上面的图像；你能认出任何图案或图像吗？</p><p id="1181" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">如果是这样，恭喜你。如果没有，放松；你没有错过任何东西；只需缩小前面图像的尺寸，然后再次进行分析。</p><h2 id="7486" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">聚焦无监督机器学习:</h2><ol class=""><li id="5d74" class="ms mt iq lu b lv ml ly mm ko mu ks mv kw mw mk mx my mz na bi translated">从未标记的结构中推断出描述隐藏结构的函数的任务</li></ol><p id="d78e" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">数据=无监督学习</p><ul class=""><li id="7e58" class="ms mt iq lu b lv lw ly lz ko nb ks nc kw nd mk ne my mz na bi translated">分布/概率密度函数</li><li id="b4f2" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk ne my mz na bi translated">汇总统计数据</li></ul><p id="e025" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">2.用于从包含无标记响应的输入数据的数据集进行推断的算法。</p><h2 id="e131" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">监督学习和非监督学习的最大区别:</h2><ol class=""><li id="2808" class="ms mt iq lu b lv ml ly mm ko mu ks mv kw mw mk mx my mz na bi translated">监督学习和非监督学习之间的主要区别是对标记训练数据的要求。无监督学习使用未标记的或原始的数据，而监督学习使用标记的输入和输出训练数据。</li><li id="47ee" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">由于提供给学习者的示例是未标记的，因此评估潜在解决方案不会有错误——这将无监督学习与有监督学习区分开来。</li></ol><h2 id="f828" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">尝试理解数据中的模式</h2><p id="3e20" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">理解数据模式时我们需要问的问题:</p><ol class=""><li id="206c" class="ms mt iq lu b lv lw ly lz ko nb ks nc kw nd mk mx my mz na bi translated">哪个(些)值出现得最频繁？</li><li id="41ed" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">数据差异有多大？</li><li id="c793" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">数据围绕中心变化的对称程度如何？</li><li id="d325" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">数据是否围绕值聚集在一起？</li><li id="7963" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">数据“集中”的子空间</li></ol><p id="5803" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">让我们分析以下数据，了解一些集群的基本概念，以及在执行集群时我们需要记住的内容:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nk"><img src="../Images/3a35885b1e4969ec756f6f22fd98af97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Rk8I6r0BQT6TtbnY"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">作者图片</figcaption></figure><h2 id="e9e8" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">聚类:</h2><p id="90e4" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">在许多数据科学应用中，另一种重要的联系是数据集各行之间的相似性。这就是所谓的集群。</p><h2 id="2c1e" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">例如:</h2><ol class=""><li id="de60" class="ms mt iq lu b lv ml ly mm ko mu ks mv kw mw mk mx my mz na bi translated">各列之间的关系:我们可能需要了解年龄和收入是否相关，或者收入和家庭规模是否与信用卡平均余额相关。</li><li id="6a53" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">行之间的关系:另外，我们需要知道人3是否与人6相似，人4是否与人5或9相似，等等。我们可以根据人们的相似程度来对他们进行分类吗？</li></ol><h2 id="a731" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">快速问题第一部分:</h2><p id="0617" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">我们什么时候可以对数据进行聚类？当然，我们不能随机聚集任何数据。</p><p id="56b4" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">所以，</p><p id="03e1" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">1.彼此相似(接近)的数据实例在同一个集群中。</p><p id="bbb8" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">2.彼此不同(相距很远)的数据实例位于不同的集群中。</p><h2 id="f663" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">集群的质量/类型:</h2><h2 id="ea8a" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">1.集群内凝聚力(紧密度):</h2><p id="d53f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">内聚性衡量聚类中的数据点与聚类质心的接近程度。</p><h2 id="d17c" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">2.集群间分离:(隔离):</h2><p id="77d5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">分离意味着不同的质心应该彼此远离。</p><p id="a959" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir">注意:距离的概念是以上所有内容的中心。</strong></p><h2 id="5721" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">快速问题第2部分:</h2><p id="503f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated"><strong class="lu ir">我们刚刚了解了距离、分离和隔离，但是，如何准确地计算距离呢？</strong></p><p id="d205" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">不用担心:这就是数学的数值方法发挥作用的地方。</p><h2 id="aca4" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">方法1:欧几里德距离或L范数:</h2><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nl"><img src="../Images/4e638d2a3e80b46dbaa2d18c235ab328.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BRJOmtNokFzx4bkZ"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated"><a class="ae lr" href="https://www.gstatic.com/education/formulas2/472522532/en/euclidean_distance.svg" rel="noopener ugc nofollow" target="_blank">https://www . gstatic . com/education/formulas 2/472522532/en/euclidean _ distance . SVG</a></figcaption></figure><p id="fa55" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir">符号:</strong></p><p id="4262" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">p，q =欧几里德n-空间中的两点。</p><p id="87ae" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">pi，qi =欧几里得向量，从空间的原点(初始点)开始</p><p id="cafc" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">n = n空间</p><h2 id="b09e" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">方法2:曼哈顿距离或L1范数:</h2><p id="6b7f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">曼哈顿距离也称为城市街区距离，通过公式计算得出</p><p id="0abb" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">|x2-x1|+|y2-y1|</p><h2 id="c137" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">方法3:闵可夫斯基距离或LQ范数:</h2><p id="f216" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">公式:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nm"><img src="../Images/d3b110f66a59bc71cbc7306e5711380c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*y_t7Hy8MO5EA-9XO"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated"><a class="ae lr" href="https://cdn-images-1.medium.com/max/800/1*IU0JIkFXjqGEKHtwxPoIiw.png" rel="noopener">https://cdn-images-1 . medium . com/max/800/1 * iu0 jikfxjqgekhtwxpoiiw . png</a></figcaption></figure><h2 id="8579" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">注意:</h2><p id="aede" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">无监督和有监督学习以及各自的算法都是工具，我们只需要明白什么时候用什么！</p><p id="9030" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">不浪费太多时间，让我们转到博客的另一个更有趣的部分，即理解关联规则挖掘和其他相关的东西。</p><h2 id="7837" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">聚类有几种有趣的算法可供尝试:</h2><p id="4b8f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated"><strong class="lu ir"> 1。K-MEANS: </strong></p><p id="00f5" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">K-MEANS是一种分割聚类算法，因为它将给定的数据分割成K个聚类。</p><p id="c386" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">1.每个聚类都有一个聚类中心，称为质心。</p><p id="092b" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">2.k由用户指定。</p><p id="f4f8" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir"> 2。凝聚层次聚类:</strong></p><p id="1798" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">这是一种分层聚类算法，因为它创建了聚类和子聚类的层次结构。</p><p id="8d5e" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">1.从每个点开始，作为一个单独的集群。</p><p id="34ed" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">2.重复合并两个最接近的聚类，直到出现一个单一的、无所不包的聚类。</p><p id="087c" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir"> 3。数据库扫描:</strong></p><p id="b21b" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">这是一个基于密度的分区聚类算法。</p><p id="e76c" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">1.聚类数由算法自动确定。</p><p id="7f31" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">2.低密度区域中的点被分类为噪声并被省略。</p><h2 id="563c" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">让我们深入研究这些算法，看看它实际上是如何工作的？</h2><h2 id="5254" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">k均值聚类:</h2><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mq"><img src="../Images/2528c3fea6ee12bf45a5d11c51265c14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BdjfU-xb9qC7UNME"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">作者图片</figcaption></figure><p id="0a59" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir">试着分析一下图形。</strong></p><p id="b68f" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">让我们简单看看上图中的情况以及K-means聚类的工作原理。</p><ol class=""><li id="7551" class="ms mt iq lu b lv lw ly lz ko nb ks nc kw nd mk mx my mz na bi translated">假设K =2</li><li id="6b6f" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">因此，这里的两个质心(红星和蓝星表示为质心)是随机初始化的。</li><li id="16a5" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">更靠近质心的点被分配给该聚类。</li><li id="809e" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">简而言之，重新计算每个簇(质心)中的点。</li></ol><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mq"><img src="../Images/7578468345de468105847bae35751493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iALMtc9csxzJyXOV"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">作者图片</figcaption></figure><p id="6567" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir">这里发生了什么？</strong></p><p id="851f" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">在上面的图中，点被重新分配给它们的质心(星)更接近的簇，并且该过程重复直到算法收敛。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mq"><img src="../Images/cd0b1b3d91f26710ed791c7db7f956e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kCvExfHpt85TaOrV"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">作者图片</figcaption></figure><p id="eb7a" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir">最终图形</strong></p><p id="ea93" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">最后一步包括不再改变质心的位置，因为聚类算法已经收敛。</p><h2 id="7ffd" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">我们到目前为止在K-MEANS聚类中所看到的内容的简短总结:</h2><p id="7d81" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">→给定K，K均值算法工作如下:</p><ol class=""><li id="c9cb" class="ms mt iq lu b lv lw ly lz ko nb ks nc kw nd mk mx my mz na bi translated">随机选择K个数据点(也称为种子，我们取k = 2)作为初始质心(即聚类中心)。</li><li id="284e" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">将每个数据点分配给最近的质心</li><li id="7e4f" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">使用当前群集成员重新计算质心。</li><li id="864a" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">如果不满足收敛标准，或者如果一些聚类没有得到任何点，则再次转到步骤2并重复。</li></ol><h2 id="3fbe" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">到底什么是停止或收敛标准:</h2><ol class=""><li id="14ef" class="ms mt iq lu b lv ml ly mm ko mu ks mv kw mw mk mx my mz na bi translated">没有(或最少)将数据点重新分配给不同的集群</li><li id="1efe" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">质心无变化(或变化最小)。</li><li id="8743" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">或者成本函数的最小减少，误差平方和(SSE)，</li></ol><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/61367e7eaaa686475961c0abd2c27c35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/0*5x_ECPxs5FPvyW12"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated"><a class="ae lr" href="https://www.gstatic.com/education/formulas2/472522532/en/residual_sum_of_squares.svg" rel="noopener ugc nofollow" target="_blank">https://www . gstatic . com/education/formulas 2/472522532/en/residual _ sum _ of _ squares . SVG</a></figcaption></figure><p id="08b7" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir">符号:</strong></p><p id="39f0" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">其中Ck是k^th聚类，ck是聚类Ck的质心(Ck中所有数据点的平均向量)，距离是两个对象之间的标准欧几里得距离。</p><h2 id="fdd6" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">要记住K-MEANS的局限性:</h2><ol class=""><li id="e440" class="ms mt iq lu b lv ml ly mm ko mu ks mv kw mw mk mx my mz na bi translated">随着SSE的增加，离群值可能会导致问题，或者小集群可能会与离群值结合在一起，从而提供不自然的集群。</li><li id="45c1" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">无法正确处理分类数据或混合数据。</li><li id="926c" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">最初，当质心是随机的时，结果可能会根据簇的不同而不同。</li><li id="1f44" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">非凸簇处理不好。</li></ol><h2 id="b9c8" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">K-MEANS局限性的解决方案:</h2><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nm"><img src="../Images/22502c43f96df1366d56a1fcbbbdfa2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*r65LvNGDSZ1Iina7"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">作者图片</figcaption></figure><p id="d061" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">向前发展…</p><h2 id="2e2c" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">2]凝聚层次聚类(AHC):</h2><h2 id="c4e2" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">AHC算法的工作原理:</h2><ol class=""><li id="839a" class="ms mt iq lu b lv ml ly mm ko mu ks mv kw mw mk mx my mz na bi translated">首先将所有点作为单独的聚类，也就是将每个项目分配到它自己的聚类中，这样，如果你有N个项目，你现在有N个聚类，每个聚类只包含一个项目。</li><li id="1cdc" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">在每一步，合并两个最接近的集群，直到只剩下一个集群</li><li id="a630" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">计算新分类和每个旧分类之间的距离(相似性)。</li><li id="1ac8" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">重复第2步和第3步，直到所有项目都聚集成一个大小为n的簇。</li></ol><h2 id="7376" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">要记住的关键操作:</h2><ol class=""><li id="8b63" class="ms mt iq lu b lv ml ly mm ko mu ks mv kw mw mk mx my mz na bi translated">这需要聚类邻近度的定义，即距离矩阵或邻近度矩阵。所以，这也是一种类似K-Means的基于距离的算法。</li><li id="7162" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">各种凝聚层次技术的区别在于它们定义邻近性的方式。</li></ol><h2 id="2b87" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">它与K-MEANS算法有什么不同？</h2><ol class=""><li id="a351" class="ms mt iq lu b lv ml ly mm ko mu ks mv kw mw mk mx my mz na bi translated">k没有被指定为先验的。但是，需要一个终止条件。</li><li id="1474" class="ms mt iq lu b lv nf ly ng ko nh ks ni kw nj mk mx my mz na bi translated">因为每对点之间的距离是为邻近矩阵计算的。</li></ol><h2 id="d80d" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">示例:</h2><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nm"><img src="../Images/d69e0776fc46152d8db12a9998624622.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*o0Rs8BtdMlWQkIMF"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated"><a class="ae lr" href="https://www.researchgate.net/profile/Carsten-Walther/publication/273456906/figure/fig3/AS:294866065084419@1447312956501/Example-of-hierarchical-clustering-clusters-are-consecutively-merged-with-the-most.png" rel="noopener ugc nofollow" target="_blank">https://www . researchgate . net/profile/Carsten-Walther/publication/273456906/figure/fig 3/AS:294866065084419 @ 1447312956501/Example-of-hierarchical-clustering-clusters-is-successfully-merged-with-the-most . png</a></figcaption></figure><h2 id="4d45" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">让我们了解一下群集之间的邻近距离:</h2><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nm"><img src="../Images/4ad3a943800f314ccf08f3fba65473e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JbcPNR-PhOVJxYJg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated">作者图片</figcaption></figure><h2 id="e9d0" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">最不喜欢NOTT:</h2><h2 id="ab20" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">3]DBS can:[带噪声的应用程序的基于密度的空间聚类]:</h2><p id="8b1f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated"><strong class="lu ir"> DBSCAN处理三种类型的数据点，即</strong></p><p id="f421" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir"> 1。核心要点:</strong></p><p id="b3c1" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">如果一个点在eps中有超过个分点，那么它就是核心点。</p><p id="162a" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">1。EPS  =通常，当我们谈论密度时，通常困扰我们的问题是如何估计密度，因此在这里，密度是通过计算数据集中特定点的指定半径EPS内的点数来估计的。</p><p id="7717" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir"> 2。MinPts </strong> =这里MinPts是eps半径的最小数据点数的缩写形式。最小值必须等于3。</p><p id="9414" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir">经验法则:如果有“p”个变量，那么min pts&gt;= p+1】</strong></p><p id="4677" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir"> 2。边界点:</strong></p><p id="7ff2" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">在eps中比MinPts低但在核心点邻域内的点。</p><p id="a00a" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir"> 3。噪声点或异常值:</strong></p><p id="e0e6" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">既不是核心也不是边界的点。</p><h2 id="1875" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">算法的工作原理:</h2><p id="a805" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">1.从x中随机选取一个从未被访问过的数据点。</p><p id="4cbe" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">2.如果eps内的点数&gt; MinPts，则创建一个聚类；否则将其标记为噪声</p><p id="57fa" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">a.对于这个新群集中的每个点，重复(ii)</p><p id="38dd" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">3.重复，直到所有的点都用尽。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi no"><img src="../Images/2852c2029e581c4ed9a37dde64f601c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MvW5pF6L3uw6agLA"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk translated"><a class="ae lr" href="https://cdn-images-1.medium.com/max/1600/1*tc8UF-h0nQqUfLC8-0uInQ.gif" rel="noopener"><em class="np">https://cdn-images-1 . medium . com/max/1600/1 * tc8UF-h0 nqquflc 8-0 uinq . gif</em></a></figcaption></figure><h2 id="612a" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">集群符合网络安全:</h2><p id="a94c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated">网络安全集群可用于多种目的，包括:</p><p id="5c83" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">聚类分析简单地说就是将在整个网络中发现的彼此相似的数据点分组，以揭示隐藏和异常的活动模式，并检测网络安全攻击，否则通过从单个数据点分析整个问题将无法检测到这些攻击。</p><p id="ec37" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">我试图展示我们如何利用聚类分析来定位恶意软件数据集中的模式，因为聚类是一种无监督的机器学习方法，能够检测奇怪的恶意软件攻击模式并识别恶意软件行为。</p><p id="ac73" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">在这种情况下，我实现了K-means聚类检测技术，根据恶意软件的属性来检测数据中的恶意软件行为。找到之前案例研究的Jupyter笔记本，请在最后告诉我们您的发现:)</p><h2 id="2653" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">GITHUB GIST :❤️</h2><p id="2ae8" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma ko mn mc md ks mo mf mg kw mp mi mj mk ij bi translated"><strong class="lu ir">从卡格尔那里拿到问题陈述:在这里提交👇🏻</strong></p><p id="3a95" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><a class="ae lr" href="https://www.kaggle.com/datasets/piyushrumao/malware-executable-detection" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/piyushrumao/malware-executable-detection</a></p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="65cd" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir">关注我们学习数据科学博客和文章的乐趣:</strong></p><p id="3780" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">领英<strong class="lu ir">:</strong><a class="ae lr" href="https://www.linkedin.com/company/dsmcs/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/company/dsmcs/</a></p><p id="d96e" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">https://www.instagram.com/datasciencemeetscybersecurity/?hl=en </p><p id="4d99" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">GITHUB:<a class="ae lr" href="https://github.com/Vidhi1290" rel="noopener ugc nofollow" target="_blank">https://github.com/Vidhi1290</a></p><p id="60d3" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">https://twitter.com/VidhiWaghela</p><p id="8e5a" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated">中:<a class="ae lr" href="https://datasciencemeetscybersecurity.blogspot.com/" rel="noopener ugc nofollow" target="_blank">https://medium.com/@datasciencemeetscybersecurity-</a></p><p id="9dd1" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma ko mb mc md ks me mf mg kw mh mi mj mk ij bi translated"><strong class="lu ir"> -团队数据科学遇上网络安全❤️💙</strong></p></div></div>    
</body>
</html>