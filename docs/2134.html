<html>
<head>
<title>Phishing Domain Detection using Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于神经网络的网络钓鱼领域检测</h1>
<blockquote>原文：<a href="https://infosecwriteups.com/phishing-domain-detection-using-neural-networks-b133a6495a78?source=collection_archive---------1-----------------------#2022-06-15">https://infosecwriteups.com/phishing-domain-detection-using-neural-networks-b133a6495a78?source=collection_archive---------1-----------------------#2022-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/0f475ad814319ad9da9221f53a587ff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*quHtZCsfOml6gtt0_FUTmw.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" href="https://blog.idrive.com/2018/10/10/dont-be-a-victim-some-tips-to-avoid-phishing-scams/" rel="noopener ugc nofollow" target="_blank">https://blog . idrive . com/2018/10/10/don ' t-be-a-victim-some-tips-to-avoid-phishing-scams/</a></figcaption></figure><div class=""/><div class=""><h2 id="1ade" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">神经网络在域名分析中的应用</h2></div><h1 id="e966" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">域名分析</h1><p id="0855" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated"><a class="ae jg" href="https://github.com/wesleyraptor/streamingphish/" rel="noopener ugc nofollow" target="_blank"> StreamingPhish </a>是域名分析的实现之一。域名分析背后的想法是训练已知良性和网络钓鱼域的精选数据。在StreamingPhish中，一个348维的特征向量从域名中导出，然后使用<a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>进行训练。一些功能包括:</p><ol class=""><li id="7349" class="mm mn jj ls b lt mo lw mp lz mq md mr mh ms ml mt mu mv mw bi translated">如果域名中存在品牌名称</li><li id="73b4" class="mm mn jj ls b lt mx lw my lz mz md na mh nb ml mt mu mv mw bi translated">如果某些定义的网络钓鱼词汇存在于StreamingPhish作者从<a class="ae jg" href="https://github.com/SwiftOnSecurity/PhishingRegex/blob/master/PhishingRegex.txt" rel="noopener ugc nofollow" target="_blank">https://github . com/swifton security/PhishingRegex/blob/master/PhishingRegex . txt</a>中精心挑选的目录中</li><li id="7b07" class="mm mn jj ls b lt mx lw my lz mz md na mh nb ml mt mu mv mw bi translated">如果存在与钓鱼文字相似的文字，则相似度定义为<a class="ae jg" href="https://en.wikipedia.org/wiki/Levenshtein_distance" rel="noopener ugc nofollow" target="_blank"> Levenshtein距离</a></li><li id="996c" class="mm mn jj ls b lt mx lw my lz mz md na mh nb ml mt mu mv mw bi">…</li></ol><p id="fe7d" class="pw-post-body-paragraph lq lr jj ls b lt mo kk lv lw mp kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">这些都是很棒的特性，作者展示了非常好的结果(测试结果的准确率为98.9%)。在这篇文章中，首先，我们将尝试看看我们是否可以在神经网络中使用这些功能，以及我们会得到什么样的结果，然后最终我们是否可以完全摆脱这些功能。</p><h1 id="f528" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">简单神经网络</h1><p id="a6bc" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">首先，我们将在TensorFlow 示例中创建一个类似于<a class="ae jg" href="https://www.tensorflow.org/datasets/keras_example#step_2_create_and_train_the_model" rel="noopener ugc nofollow" target="_blank"> MNIST的网络。该网络具有要素形状的输入图层。在MNIST，它是二维的，但在我们这里，它是一维的，大小为348。然后，我们有一个由128个节点组成的密集层，最后是良性与网络钓鱼类的两个输出节点。</a></p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="e285" class="pw-post-body-paragraph lq lr jj ls b lt mo kk lv lw mp kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">上面的代码实现了我们刚刚讨论的内容。我们还获得了98.9%的测试精度，这与现有的方法相当。虽然这些是有趣的结果，但我们从中获得了什么呢？我们还没有提高准确性(请注意，我们没有进行模型选择和交叉验证，所以我们应该从最初的实现中获得结果，这是有保留的。)或去掉了特性的必要性。因此，让我们去掉特性的必要性，看看我们的进展如何？</p><h1 id="6734" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">基于嵌入的卷积神经网络</h1><p id="41f1" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">用一维卷积嵌入是一种非常简单的文本分类方法。在我们的场景中，文本是一个域名，我们的目标是将它们分类为良性或网络钓鱼。下面是一个很棒的StackOverflow线程，解释了它的工作原理:【Keras 1d卷积层如何处理单词嵌入—文本分类问题？(过滤器、内核大小和所有超参数)</p><p id="9b08" class="pw-post-body-paragraph lq lr jj ls b lt mo kk lv lw mp kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">我们的简单模型看起来类似于StackOverflow线程中的模型:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="8dbd" class="pw-post-body-paragraph lq lr jj ls b lt mo kk lv lw mp kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">在我们的场景中，我们使用下面的代码将域名的每个字符转换为它的ASCII值，这使得嵌入词汇表的大小为128(嵌入层的第一个参数)。</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">转换成ascii码</figcaption></figure><p id="5abf" class="pw-post-body-paragraph lq lr jj ls b lt mo kk lv lw mp kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">convert_to_ascii方法获取字符串，并基于预定义的最大长度，使用数据中最大的字符串或手动选择，将字符串字符转换为它们的ascii值。</p><p id="14cb" class="pw-post-body-paragraph lq lr jj ls b lt mo kk lv lw mp kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">对于该模型，我们得到96.12%的测试准确度，这低于使用精选特征和使用逻辑回归和简单神经网络的学习。虽然同时这个模型并不真的需要预定义的特性，所以它更通用。</p><h1 id="fedb" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">基于LSTM的神经网络</h1><p id="195c" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">LSTM广泛用于文本分类，因此我们用它们构建了一个简单的网络:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="d4ba" class="pw-post-body-paragraph lq lr jj ls b lt mo kk lv lw mp kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">这个模型的结果要差得多，给出的测试准确率为93.19%。尽管它没有同时被优化。</p><h1 id="873e" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">无特征输入:神经网络性能</h1><p id="531e" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">即使在一个简单的设置中，无特征的神经网络输入比有特征的更糟糕，我们认为它们是有价值的，因为它们可以被一般化并处理不同的场景。对于我们来说，接下来的步骤如下，看看我们是否可以提高性能:</p><ol class=""><li id="38f3" class="mm mn jj ls b lt mo lw mp lz mq md mr mh ms ml mt mu mv mw bi translated">一般来说，数据越多，神经网络的性能越好。在这个设置中，我们有大约10k+样本，这不是很多，因此包含更多数据将是查看我们是否可以提高性能的一种方法</li><li id="efab" class="mm mn jj ls b lt mx lw my lz mz md na mh nb ml mt mu mv mw bi translated"><a class="ae jg" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank">拥抱脸</a>有很好的标记器和文本分类模型，所以值得研究一下</li><li id="2c54" class="mm mn jj ls b lt mx lw my lz mz md na mh nb ml mt mu mv mw bi translated">优化当前简单模型的超参数将是研究改进性能的另一种方法</li></ol><h1 id="c9dc" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">谷歌Colab笔记本</h1><p id="3dca" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">为了让StreamingPhish代码直接在Google Colab笔记本中工作，我们做了一些更改:</p><ol class=""><li id="18c9" class="mm mn jj ls b lt mo lw mp lz mq md mr mh ms ml mt mu mv mw bi translated">我们从GitHub下载了StreamingPhish并解压。然后我们安装了一些依赖项。</li></ol><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="9d48" class="pw-post-body-paragraph lq lr jj ls b lt mo kk lv lw mp kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">2.之后，我们做了一些路径的改变。由于解压缩发生在您所在的当前目录Colab中，因此我们提供了一个相对路径:</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="d824" class="pw-post-body-paragraph lq lr jj ls b lt mo kk lv lw mp kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">3.脚本的其余部分保持不变，并按原样执行。这是最终的笔记本，请在驱动器中保存一份副本，尽情享受吧:</p><div class="is it gp gr iu nl"><a href="https://colab.research.google.com/gist/SalilJain/84f78722ff3007fed49da2cbb353cb77/phishing.ipynb#scrollTo=TxtKFgkQSN5j" rel="noopener  ugc nofollow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd jk gy z fp nq fr fs nr fu fw ji bi translated">谷歌联合实验室</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">网络钓鱼</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">神经网络检测</p></div></div><div class="nu l"><div class="nv l nw nx ny nu nz ja nl"/></div></div></a></div><p id="9c42" class="pw-post-body-paragraph lq lr jj ls b lt mo kk lv lw mp kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">Medium是一个很好的平台，可以了解最新最棒的技术。如果你不是会员，请考虑使用我的推荐链接:<a class="ae jg" href="https://salilkjain.medium.com/membership" rel="noopener">https://salilkjain.medium.com/membership</a>成为会员，我会收到你的一部分会员费。在<a class="ae jg" href="https://www.linkedin.com/in/jainsalil/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae jg" href="https://twitter.com/stridefrodo" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上与我联系。</p></div></div>    
</body>
</html>