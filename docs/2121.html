<html>
<head>
<title>Detecting DNS Tunneling using Spark Structured Streaming</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Spark结构化流检测DNS隧道</h1>
<blockquote>原文：<a href="https://infosecwriteups.com/detecting-dns-tunneling-using-spark-structured-streaming-c7e2b6af0349?source=collection_archive---------0-----------------------#2022-06-07">https://infosecwriteups.com/detecting-dns-tunneling-using-spark-structured-streaming-c7e2b6af0349?source=collection_archive---------0-----------------------#2022-06-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/68d496381ace9cce0b4f9b580976fb3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3_2FywRePkmco2Q5Cd-U5A.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" href="https://bluecatnetworks.com/blog/why-you-should-pay-attention-to-dns-tunneling/" rel="noopener ugc nofollow" target="_blank">https://blue cat networks . com/blog/why-you-should-notice-to-DNS-tunneling/</a></figcaption></figure><div class=""/><div class=""><h2 id="850e" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">从生成DNS日志到结构化流的端到端实施</h2></div><h1 id="d944" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">域名服务器(Domain Name Server)</h1><p id="2069" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在我们开始描述DNS隧道以及如何使用Spark结构化流检测它之前，先简要说明一下DNS。</p><p id="9840" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">DNS代表域名系统，即使你可能没有明确地使用它，尽管你的机器在进入这个页面之前肯定使用过它。当你点击链接进入这个页面时，或者如果你在浏览器窗口中手动输入，你的机器使用DNS将域名medium.com转换成IP地址。有一个简洁的工具<a class="ae jg" href="https://www.nslookup.io/" rel="noopener ugc nofollow" target="_blank"> nslookup.io </a>可以显示任何域的A和其他记录。这里是medium.com的详细情况。类似地，您的机器查找medium.com的记录，以找到medium.com的IP地址，并最终连接到它，以便您的浏览器可以呈现它。</p><h1 id="7652" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">DNS隧道</h1><p id="75a1" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在企业中，通常不会对DNS流量进行高度过滤/监控。由于这一特性，即使协议本身不是为数据传输而设计的，它也是攻击者从受损机器发送或接收数据的绝佳选择。</p><blockquote class="mr ms mt"><p id="b659" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated"><strong class="ls jk"> DNS隧道</strong>是一种在DNS查询和响应中对其他程序或协议的数据进行编码的网络攻击方法。DNS隧道通常包括数据有效负载，这些数据有效负载可以添加到受攻击的DNS服务器，并用于控制远程服务器和应用程序。</p><p id="5eec" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">来源:<a class="ae jg" href="https://www.infoblox.com/glossary/dns-tunneling" rel="noopener ugc nofollow" target="_blank">https://www.infoblox.com/glossary/dns-tunneling</a></p></blockquote><p id="2dc4" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">所以基本上，攻击者将数据本身编码在DNS查询和响应中。通常情况下，DNS查询将由受危害系统上的恶意负载执行，并用于泄漏数据。DNS响应将用于向受损机器发送命令。</p><h1 id="2c2a" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">DNS日志</h1><p id="5271" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">为了检测DNS隧道，我们需要日志。对于这篇博文，我们将生成这些日志。根据您的企业使用的DNS解决方案，您的日志会有所不同。Infoblox是企业十大DNS提供商之一。<a class="ae jg" href="https://docs.infoblox.com/display/NAG8/Capturing+DNS+Queries+and+Responses" rel="noopener ugc nofollow" target="_blank">捕获DNS查询和响应</a>提供了DNS查询的示例日志。以下是显示查询的DNS日志的格式:</p><blockquote class="mr ms mt"><p id="6477" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated"><code class="fe my mz na nb b">&lt;dd-mmm-YYYY HH:MM:SS.uuu&gt; &lt;client IP&gt;#&lt;port&gt; query: &lt;query_Domain name&gt; &lt;class name&gt; &lt;type name&gt; &lt;- or +&gt;[SETDC] &lt;(name server ip)&gt;</code></p><p id="5956" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">其中<br/><code class="fe my mz na nb b">+ = recursion</code><br/><code class="fe my mz na nb b">- = no recursion</code><br/><code class="fe my mz na nb b">S = TSIG</code><br/><code class="fe my mz na nb b">E = EDNS option set</code><br/><code class="fe my mz na nb b">T = TCP query</code><br/><code class="fe my mz na nb b">D = EDNS ‘DO’ flag set</code><br/><code class="fe my mz na nb b">C = ‘CD’ message flag set</code></p><p id="ec1a" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">DNS查询消息示例:</p><p id="9044" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated"><code class="fe my mz na nb b">30-Apr-2013 13:35:02.187 client 10.120.20.32#42386: query: foo.com IN A + (100.90.80.102)</code></p></blockquote><p id="06bd" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">对于DNS隧道，我们会对来自机器的大量DNS查询感兴趣。在此示例查询中，来自客户端10.120.20.32的是foo.com。对于DNS隧道查询将有子域，因为攻击者会将数据编码到其中，而域(即foo.com)和域的权威DNS服务器由攻击者控制。</p><h2 id="6bc3" class="nc kz jj bd la nd ne dn le nf ng dp li lz nh ni lk md nj nk lm mh nl nm lo nn bi translated">正在生成DNS日志</h2><p id="86fe" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我们将从一台机器上生成假的DNS查询日志数据。我们需要的是时间戳和查询更改来模拟DNS隧道攻击。例如，如果想要在Y分钟内识别特定域的X个唯一的查询，我们必须在生成数据时记住这一点。</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ns nt l"/></div></figure><blockquote class="mr ms mt"><p id="0359" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">上面的代码生成以下示例:</p><p id="1b76" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">12-May-2022 13:35:02.187客户端10.120.20.32#42386:查询:HsilYPOU1qHHgCA.foo.com在A+(100.90.80.102)</p></blockquote><p id="d1d1" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我们生成随机子域(在真实攻击中，它们会编码数据)来模拟DNS隧道。现在我们必须生成带有各种时间戳的数据来模拟多个DNS隧道查询。</p><h2 id="dd3e" class="nc kz jj bd la nd ne dn le nf ng dp li lz nh ni lk md nj nk lm mh nl nm lo nn bi translated">结构化DNS日志</h2><p id="f3f8" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">到目前为止，我们已经生成了非结构化日志。我们将解析它们，从中提取字段，并创建一个可以写入的Spark数据帧。</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="e043" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">上面的代码按空间分割日志，然后使用这些部分来创建结构化数据。我们还使用<a class="ae jg" href="https://pypi.org/project/tld/" rel="noopener ugc nofollow" target="_blank"> tld </a>库从查询中获取精确的fld和子域。</p><h2 id="41d9" class="nc kz jj bd la nd ne dn le nf ng dp li lz nh ni lk md nj nk lm mh nl nm lo nn bi translated">随着时间的推移生成DNS日志</h2><p id="4fae" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">现在让我们设置X和y。让我们尝试在10分钟内检测200个不同的查询。这样X=200，Y= 10分钟。因此，我们需要以一定的频率生成数据，在10分钟内累计创建200个不同的查询。另一点是，我们不想一次生成所有数据，而是可能每分钟左右以“流式方式”生成，以模拟它在DNS解决方案提供商日志系统中的表现。</p><p id="9660" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">下面的代码在给定时间Y=10分钟内生成日志。方法<em class="mu"> dns_logs </em>在给定域的开始和结束时间戳之间生成<em class="mu"> num_logs </em>日志。我们调用<em class="mu"> generate_logs </em>，它每分钟调用<em class="mu"> dns_logs </em> <em class="mu">，生成大约20个日志(<em class="mu">num _ logs _ per _ minute</em>= 200/10)。</em></p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ns nt l"/></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">正在生成DNS日志</figcaption></figure><h2 id="f044" class="nc kz jj bd la nd ne dn le nf ng dp li lz nh ni lk md nj nk lm mh nl nm lo nn bi translated">火花结构化流</h2><p id="6b3b" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">现在我们有了生成数据的代码，让我们编写一些代码来使用<a class="ae jg" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank"> Spark结构化流</a>读取数据，以最终检测DNS隧道。</p><p id="a18c" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">首先，我们设置读取和写入数据的位置。将从临时目录中的<em class="mu"> dns_logs </em>目录读取数据。我们在temp目录中创建一个<em class="mu">流</em>位置，用于存储来自流作业的其他写入。将被写入<em class="mu">流</em>位置的<em class="mu">输出</em>目录。为了从故障中恢复，我们需要提供一个检查点位置。为此，我们在同一个<em class="mu">流</em>位置提供了一个<em class="mu">检查点</em>目录。</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="64c0" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">以下是流式作业的完整代码:</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="d475" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">请注意，如果流位置存在，我们会将其删除，但在生产作业中我们不会这样做。这仅用于测试目的。如果我们在生产中也这样做，我们将丢失输出数据以及要从中恢复的检查点。</p><p id="50f0" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我们正在使用<a class="ae jg" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#creating-streaming-dataframes-and-streaming-datasets" rel="noopener ugc nofollow" target="_blank">文件源</a>进行流式作业。因为我们正在写入orc数据，所以我们使用它来读取它。为了处理迟到的数据，我们提供了60秒的<a class="ae jg" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#handling-late-data-and-watermarking" rel="noopener ugc nofollow" target="_blank">水印</a>。在这种情况下，我们知道我们的数据最多会晚60秒到达，我们应该没问题，但是可能需要根据他们的系统进行更改。然后，我们按照10分钟的时间窗口和5分钟的幻灯片以及领域进行分组。这将为我们提供从每5分钟开始的10分钟窗口。例如，12:00–12:10、12:05–12:15、12:10–12:20等等。我们选择10分钟，因为我们希望在10分钟内检测到唯一数量的子域查询。幻灯片帮助我们考虑这些事件开始时的情形，比如说在窗口中间。例如，如果我们没有幻灯片，我们的窗口将是12:00–12:10、12:10–12:20等等。在这种情况下，我们将无法检测查询是否一致地发生在12:05–12:15之间。我们可以有一个更细粒度的幻灯片来说明在任何时间点开始的事件，这将创建更多的<em class="mu">输出</em>数据，以及流作业保留在内存中的内容。因此，我们必须在生成的数据量和检测粒度之间取得平衡。分组之后，我们使用<em class="mu"> collect_set </em>方法聚集所有唯一的<em class="mu">子域</em>。最后，我们设置检查点并以<em class="mu"> parquet </em>格式写入输出。在这一点上，我们没有做完整的检测，因为我们只是在一段时间(窗口)内聚合所有唯一的子域DNS查询。让我们看看它是什么样子的。</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nu"><img src="../Images/e45055c95b192384179eec542d639260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ppXvZyrB426ng2j9dDuXZw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">生成的DNS日志</figcaption></figure><p id="b767" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">上面的截图显示了生成的DNS日志文件。正如我们所看到的，文件的生成间隔为1分钟，这是有意义的，因为我们的代码在生成数据之前会休眠一段时间。现在让我们看看流是什么样子的。</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nv"><img src="../Images/f0ede4b66c01bdb84ccde823c6cbcede.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0OqJzG_8wVbl1E6Oq6LX3g.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">流式输出</figcaption></figure><p id="ca7c" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我们看到生成了许多文件，但实际上，就数据而言，大多数文件都是空的(这些文件的大小为763字节)。读取所有这些数据会产生以下结果:</p><blockquote class="mr ms mt"><p id="3c96" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">[Row(domain='foo.com '，size=142，window = Row(start = datetime . datetime(2022，6，5，11，40)，end=datetime.datetime(2022，6，5，11，50))，</p><p id="ae72" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">Row(domain='foo.com '，size=45，window = Row(start = datetime . datetime(2022，6，5，11，35)，end=datetime.datetime(2022，6，5，11，45)))]</p></blockquote><p id="9744" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这里发生的基本情况是，只有在11:35到11:45和11:40到11:50之间完成的窗口才是流式的。我们让流式作业运行，但我们仍然看不到更多的窗口。包含数据的文件的时间戳为11:46和11:51，因此它是在窗口结束后1分钟生成的。因此，这里有几个问题或要点需要注意:</p><p id="dfc4" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls jk">为什么流式作业会在传入数据窗口之后的某个时间写入？</strong>那是因为我们把水印设置为60秒。流式传输需要等待那么长时间才能看到最新的数据，一旦该时间过去，它将完成聚合并写入sing。这将在<a class="ae jg" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#starting-streaming-queries" rel="noopener ugc nofollow" target="_blank">中详细解释，此处</a>为附加模式(默认模式):</p><blockquote class="mr ms mt"><p id="c0d3" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">附加模式使用水印来删除旧的聚合状态。但是窗口聚合的输出被延迟到<code class="fe my mz na nb b">withWatermark()</code>中指定的延迟阈值，因为根据模式语义，行只能在最终确定后(即越过水印后)添加到结果表中一次。</p><p id="c8a9" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">来源:<a class="ae jg" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#starting-streaming-queries" rel="noopener ugc nofollow" target="_blank">https://spark . Apache . org/docs/latest/structured-streaming-programming-guide . html # starting-streaming-queries</a></p></blockquote><p id="ea9d" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">因此，如果我们在Y周期内使用Z水印检测X个唯一查询，最终聚合将在Y+Z时间后写入。如果Y是24小时，Z是1小时，那么最终结果将在窗口开始后的第25小时写入。假设X在窗口开始后的N小时内到达，但我们需要再等Y-N+Z小时才能检测到。这在很多网络安全场景中是不可接受的。稍后我们将使用<a class="ae jg" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#using-foreach-and-foreachbatch" rel="noopener ugc nofollow" target="_blank"> <strong class="ls jk"> foreachBatch </strong> </a>来解决这个问题。</p><p id="9f3e" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls jk">为什么我们看不到其他窗口？</strong>原因是不再有源数据传入，这将触发写操作。因此，我们再次开始日志生成过程，因为在现实世界中，我们通常会看到连续的数据传入数据。虽然稍后我们将能够通过foreachBacth解决它。</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/fddb8f316049b62170ea31144d3ff404.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jxL4zVLnIjyiGj6ifYLFQQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">添加更多数据会触发流式作业</figcaption></figure><p id="2f3a" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">让我们看看这些文件的内容:</p><blockquote class="mr ms mt"><p id="b338" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">[Row(domain='foo.com '，size=155，window = Row(start = datetime . datetime(2022，6，5，11，45)，end=datetime.datetime(2022，6，5，11，55))，</p><p id="aa2a" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">Row(domain='foo.com '，size=142，window = Row(start = datetime . datetime(2022，6，5，11，40)，end=datetime.datetime(2022，6，5，11，50))，</p><p id="94fe" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">Row(domain='foo.com '，size=45，window = Row(start = datetime . datetime(2022，6，5，11，35)，end=datetime.datetime(2022，6，5，11，45)))]</p></blockquote><p id="3d9d" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">最后我们看到了其他的窗口。但是我们在11:45–11:55窗口中最多只能看到155个唯一查询。</p><p id="3995" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls jk">为什么不将所有200条记录汇总起来？</strong>如果我们查看生成的日志，它们从11:43开始，每分钟写一次，直到11:52。而窗口对应于11:45–11:55。所以它会丢弃时间戳小于11:45和大于11:55的日志。因此，理想情况下，我们必须设置一个比实际数量少一定百分比的阈值，但不能少到导致误报。此外，我们需要对幻灯片进行细化，目前为5分钟。</p><p id="7221" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls jk">但是我们在哪里设置这个门槛呢？</strong>到目前为止，我们已经得到了聚合的结果，但是对于这个设置，我们需要编写另一个作业来查看最近的数据，并查看是否有任何记录的大小大于或等于阈值。我们将与每批的<strong class="ls jk">再次解决这个问题。</strong></p><p id="387c" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">在我们实现foreachBatch之前，让我们先看看我们需要使用的输出模式，因为append mode会导致延迟。还有另外两种模式:更新和完成。</p><blockquote class="mr ms mt"><p id="a59f" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">更新模式使用水印删除旧的聚合状态。</p><p id="d71c" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">完整模式不会删除旧的聚合状态，因为根据定义，该模式会保留结果表中的所有数据。</p><p id="f29a" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated">来源:<a class="ae jg" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#starting-streaming-queries" rel="noopener ugc nofollow" target="_blank">https://spark . Apache . org/docs/latest/structured-streaming-programming-guide . html # starting-streaming-queries</a></p></blockquote><p id="3cd3" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">因为完整模式不会删除旧的聚合数据，所以在每个触发器上都有不必要的数据要处理。因此，我们将使用更新模式，其代码如下:</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="e0a6" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">代码与前一个类似，但对<em class="mu"> foreachBatch </em>进行了更改。<em class="mu"> foreachBatch </em>需要一个采用当前聚合数据帧和纪元ID的方法。我们为此实现了<em class="mu"> alert </em>方法，目前在该方法中，如果有超过定义阈值的唯一DNS查询，我们就打印出数据。在这种情况下，我们将实际阈值的90%定义为200，也就是180。</p><p id="1d24" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">让我们来看看生成的DNS日志中的数据:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nx"><img src="../Images/f475c89d2afa9a06ab3aa99b4cfdff21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_JXLnLfgErzz5DjffOt1Tg.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk translated">生成的DNS日志</figcaption></figure><p id="71fb" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">下面是生成的警报。这是有意义的，因为在数据写入后会立即触发流式作业并创建警报。</p><blockquote class="mr ms mt"><p id="fe34" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated"><strong class="ls jk">历元</strong> 16 <br/> <strong class="ls jk">当前时间</strong>2022–06–05 14:28:58.771419<br/><strong class="ls jk">预警</strong> [Row(domain='foo.com '，size=180，window = Row(start = datetime . datetime(2022，6，5，14，19)，end=datetime.datetime(2022，6，5，14，29))]</p><p id="f75c" class="lq lr mu ls b lt mm kk lv lw mn kn ly mv mo mb mc mw mp mf mg mx mq mj mk ml im bi translated"><strong class="ls jk">历元</strong>18<br/>T3】当前时间2022–06–05 14:29:59.090905<br/>T6】预警 [Row(domain='foo.com '，size=196，window = Row(start = datetime . datetime(2022，6，5，14，20)，end=datetime.datetime(2022，6，5，14，30))]</p></blockquote><p id="0e07" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">使用<strong class="ls jk"> <em class="mu"> foreachBatch </em> </strong>方法解决以下问题:</p><ol class=""><li id="ddad" class="ny nz jj ls b lt mm lw mn lz oa md ob mh oc ml od oe of og bi translated">现在，即使有60秒的水印，如果没有最新数据，我们也不需要等待它来获得警报。最重要的是，当我们写入文件时，除了水印时间之外，我们只会在窗口完成后获得聚合数据。使用foreachBatch，我们不需要等待，而是可以在每个触发器中获取聚合数据进行处理。</li><li id="7f5a" class="ny nz jj ls b lt oh lw oi lz oj md ok mh ol ml od oe of og bi translated">当我们写入文件时，我们没有看到所有的窗口，因为在其他窗口完成后没有触发器。foreachBatch的情况并非如此。</li><li id="0029" class="ny nz jj ls b lt oh lw oi lz oj md ok mh ol ml od oe of og bi translated">我们不需要编写另一个作业来查看聚合数据，因为我们可以在foreachBatch方法本身中编写代码。</li></ol><h1 id="ee12" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">摘要</h1><p id="6b01" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在这篇文章中，我试图从网络安全的角度简要解释DNS和DNS隧道，以及如何使用Spark结构化流来检测它。</p><p id="1a15" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">Medium是一个很好的平台，可以了解最新最棒的技术。如果你不是会员，请考虑使用我的推荐链接:<a class="ae jg" href="https://salilkjain.medium.com/membership" rel="noopener">https://salilkjain.medium.com/membership</a>成为会员，我会收取你一部分会员费。在<a class="ae jg" href="https://www.linkedin.com/in/jainsalil/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与我联系。</p></div></div>    
</body>
</html>